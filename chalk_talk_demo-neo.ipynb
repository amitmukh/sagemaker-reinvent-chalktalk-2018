{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# re:Invent Chalk Talk - Building, Training, and Deploying Fast.ai Models Using Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example application trains a fastai based image classification model using a Convolutional Neural Network (CNN) to distinguish between **Heavy Metal** and **Sports** shirts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook was created and tested on an ml.p3.2xlarge notebook instance.*\n",
    "\n",
    "Let's start by creating a SageMaker session and specifying:\n",
    "\n",
    "* The **S3 bucket** and prefix that you want to use for training and model data. This should be within the same region as the Notebook Instance, training, and hosting.\n",
    "* The **IAM role** arn used to give training and hosting access to your data. See the documentation for how to create these. Note, if more than one role is required for notebook instances, training, and/or hosting, please replace the sagemaker.get_execution_role() with appropriate full IAM role arn string(s). \n",
    "\n",
    "**IMPORTANT** please make sure the IAM role associated to your SageMaker notebook instance has the following managed IAM policies attached:\n",
    "\n",
    "* **arn:aws:iam::aws:policy/AmazonSageMakerFullAccess**\n",
    "* **arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryFullAccess**\n",
    "\n",
    "We also need to ensure there are no AWS credentials setup on the instance. We will set these up later in order to be able to train and deploy locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import random\n",
    "from io import BytesIO\n",
    "import subprocess\n",
    "from glob import glob\n",
    "\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "import requests\n",
    "import boto3\n",
    "\n",
    "import sagemaker\n",
    "from sagemaker.analytics import TrainingJobAnalytics\n",
    "from sagemaker.local import local_session\n",
    "from sagemaker.pytorch import PyTorch\n",
    "from sagemaker.predictor import RealTimePredictor, json_deserializer\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "from sagemaker.utils import name_from_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_images(images, header=None, width=\"100%\"):\n",
    "    if type(width)==type(1): width = \"{}px\".format(width)\n",
    "    html = [\"<table style='width:{}'><tr>\".format(width)]\n",
    "    if header is not None:\n",
    "        html += [\"<th>{}</th>\".format(h) for h in header] + [\"</tr><tr>\"]\n",
    "\n",
    "    for image in images:\n",
    "        html.append(\"<td><img src='{}' /></td>\".format(image))\n",
    "    html.append(\"</tr></table>\")\n",
    "    display(HTML(''.join(html)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "! if [ -e ~/.aws/credentials ]; then rm ~/.aws/credentials; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:sagemaker:Couldn't call 'get_role' to get Role ARN from role name FastaiTestLC-SageMakerIamRole-102ZYYA0VEXAJ to get Role path.\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "bucket_name = sagemaker_session.default_bucket()\n",
    "prefix = 'sagemaker/DEMO-shirts-classification'\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to pull the needed Docker images from DockerHub that are specific for running fastai based models on SageMaker. \n",
    "\n",
    "There is a project with the source code and Dockerfile that can be found at the GitHub project: https://github.com/aws-samples/amazon-sagemaker-container-with-fastai.\n",
    "\n",
    "Once we download the Docker images we then need to upload them to ECR so that they can be used by SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# get the Dockerfile from GitHub\n",
    "wget https://raw.githubusercontent.com/aws-samples/amazon-sagemaker-container-with-fastai/master/Dockerfile\n",
    "\n",
    "IMAGE=\"sagemaker-fastai\"\n",
    "\n",
    "# parameters\n",
    "FASTAI_VERSION=\"1.0\"\n",
    "PY_VERSION=\"py36\"\n",
    "\n",
    "# Get the account number associated with the current IAM credentials\n",
    "account=$(aws sts get-caller-identity --query Account --output text)\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    exit 255\n",
    "fi\n",
    "\n",
    "# Get the region defined in the current configuration (default to us-west-2 if none defined)\n",
    "region=$(aws configure get region)\n",
    "region=${region:-us-west-2}\n",
    "\n",
    "# If the repository doesn't exist in ECR, create it.\n",
    "\n",
    "aws ecr describe-repositories --repository-names \"${IMAGE}\" > /dev/null 2>&1\n",
    "\n",
    "if [ $? -ne 0 ]\n",
    "then\n",
    "    aws ecr create-repository --repository-name \"${IMAGE}\" > /dev/null\n",
    "fi\n",
    "\n",
    "# Get the login command from ECR and execute it directly\n",
    "$(aws ecr get-login --region ${region} --no-include-email)\n",
    "\n",
    "# Get the login command from ECR in order to pull down the SageMaker PyTorch image\n",
    "$(aws ecr get-login --registry-ids 520713654638 --region ${region} --no-include-email)\n",
    "\n",
    "# loop for each architecture (cpu & gpu)\n",
    "for arch in gpu cpu\n",
    "do  \n",
    "    echo \"Building image with arch=${arch}, region=${region}\"\n",
    "    TAG=\"${FASTAI_VERSION}-${arch}-${PY_VERSION}\"\n",
    "    FULLNAME=\"${account}.dkr.ecr.${region}.amazonaws.com/${IMAGE}:${TAG}\"\n",
    "    docker build -t ${IMAGE}:${TAG} --build-arg ARCH=\"$arch\"  --build-arg REGION=\"${region}\"  .\n",
    "    docker tag ${IMAGE}:${TAG} ${FULLNAME}\n",
    "    docker push ${FULLNAME}\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download training data to notebook instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be utilizing a custom data set with a mixture of pictures of heavy metal t-shirts and sport shirts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "if [ ! -d data/shirts ]; then\n",
    "    mkdir -p data/shirts\n",
    "    wget -q https://s3-eu-west-1.amazonaws.com/sagemaker-934676248949-eu-west-1/data/shirts_imgs.tar.gz\n",
    "    tar zxf shirts_imgs.tar.gz -C data/shirts\n",
    "    rm shirts_imgs.tar.gz\n",
    "fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH=f'{os.getcwd()}/data/shirts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmetal\u001b[0m/  \u001b[01;34mmodels\u001b[0m/  \u001b[01;34msport\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "%ls {DATA_PATH}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View sample images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at some of the images in the folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style='width:60%'><tr><th>Metal</th><th>Sport</th></tr><tr><td><img src='data/shirts/metal/00000365.jpg' /></td><td><img src='data/shirts/sport/00000127.jpg' /></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metal_img = random.choice(glob('data/shirts/metal/*.jpg'))\n",
    "sport_img = random.choice(glob('data/shirts/sport/*.jpg'))\n",
    "\n",
    "display_images([metal_img, sport_img],\n",
    "       header=['Metal', 'Sport'], width=\"60%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload training data to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the sagemaker.Session.upload_data function to upload our datasets to an S3 location. The return value inputs identifies the location -- we will use later when we start the training job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images exist in S3!\n",
      "training images location: s3://sagemaker-eu-west-1-934676248949/sagemaker/DEMO-shirts-classification\n"
     ]
    }
   ],
   "source": [
    "s3 = boto3.client('s3')\n",
    "key = f'{prefix}/metal/'\n",
    "response = s3.list_objects_v2(\n",
    "        Bucket=bucket_name,\n",
    "        Prefix=key,\n",
    ")\n",
    "\n",
    "if response['KeyCount'] > 0:\n",
    "    print(\"Images exist in S3!\")\n",
    "    data_location=f's3://{bucket_name}/{prefix}'\n",
    "else:\n",
    "    print(\"Training images not uploaded to S3. Uploading now\")\n",
    "    data_location = sagemaker_session.upload_data(path=DATA_PATH, bucket=bucket_name, key_prefix=prefix)\n",
    "\n",
    "print(f'training images location: {data_location}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Train locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to provide a training script that can run on the SageMaker platform. The training script is very similar to a training script you might run outside of SageMaker, but you can access useful properties about the training environment through various environment variables, such as:\n",
    "\n",
    "* `SM_MODEL_DIR`: A string representing the path to the directory to write model artifacts to. These artifacts are uploaded to S3 for model hosting.\n",
    "* `SM_OUTPUT_DATA_DIR`: A string representing the filesystem path to write output artifacts to. Output artifacts may include checkpoints, graphs, and other files to save, not including model artifacts. These artifacts are compressed and uploaded to S3 to the same S3 prefix as the model artifacts.\n",
    "\n",
    "Supposing one input channel, 'training', was used in the call to the PyTorch estimator's `fit()` method, the following will be set, following the format `SM_CHANNEL_[channel_name]`:\n",
    "\n",
    "* `SM_CHANNEL_TRAINING`: A string representing the path to the directory containing data in the 'training' channel.\n",
    "\n",
    "A typical training script loads data from the input channels, configures training with hyperparameters, trains a model, and saves a model to `model_dir` so that it can be hosted later. Hyperparameters are passed to your script as arguments and can be retrieved with an `argparse.ArgumentParser` instance. For example, the script run by this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m# Copyright 2017-2018 Amazon.com, Inc. or its affiliates. All Rights Reserved.\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# Licensed under the Apache License, Version 2.0 (the \"License\"). You\u001b[39;49;00m\r\n",
      "\u001b[37m# may not use this file except in compliance with the License. A copy of\u001b[39;49;00m\r\n",
      "\u001b[37m# the License is located at\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m#     http://aws.amazon.com/apache2.0/\u001b[39;49;00m\r\n",
      "\u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m# or in the \"license\" file accompanying this file. This file is\u001b[39;49;00m\r\n",
      "\u001b[37m# distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF\u001b[39;49;00m\r\n",
      "\u001b[37m# ANY KIND, either express or implied. See the License for the specific\u001b[39;49;00m\r\n",
      "\u001b[37m# language governing permissions and limitations under the License.\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mast\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mfastai\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mfastai.vision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mfastai.callbacks\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\r\n",
      "\r\n",
      "\u001b[37m# ignore the PIL warnings\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mwarnings\u001b[39;49;00m\r\n",
      "warnings.filterwarnings(\u001b[33m\"\u001b[39;49;00m\u001b[33mignore\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, category=\u001b[36mUserWarning\u001b[39;49;00m) \r\n",
      "\r\n",
      "\u001b[37m# setup the logger\u001b[39;49;00m\r\n",
      "logger = logging.getLogger(\u001b[31m__name__\u001b[39;49;00m)\r\n",
      "logger.setLevel(logging.DEBUG)\r\n",
      "\r\n",
      "\u001b[37m# get the host from environment variable\u001b[39;49;00m\r\n",
      "HOSTNAME = os.environ.get(\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mtrain-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\u001b[37m# define the fastai callback class to ouput metrics to CW logs for metrics\u001b[39;49;00m\r\n",
      "\u001b[30;01m@dataclass\u001b[39;49;00m\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mMetricsLogger\u001b[39;49;00m(LearnerCallback):\r\n",
      "    \u001b[37m# call when each epoch finishes to print the metrics\u001b[39;49;00m\r\n",
      "    \u001b[34mdef\u001b[39;49;00m \u001b[32mon_epoch_end\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, epoch: \u001b[36mint\u001b[39;49;00m, smooth_loss: Tensor, last_metrics: MetricsList, **kwargs: Any) -> \u001b[36mbool\u001b[39;49;00m:\r\n",
      "        last_metrics = ifnone(last_metrics, [])\r\n",
      "        stats = [(name, \u001b[36mstr\u001b[39;49;00m(stat)) \u001b[34mif\u001b[39;49;00m \u001b[36misinstance\u001b[39;49;00m(stat, \u001b[36mint\u001b[39;49;00m) \u001b[34melse\u001b[39;49;00m (name, f\u001b[33m'\u001b[39;49;00m\u001b[33m{stat:.6f}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "                 \u001b[34mfor\u001b[39;49;00m name, stat \u001b[35min\u001b[39;49;00m \u001b[36mzip\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m.learn.recorder.names[\u001b[34m1\u001b[39;49;00m:], [smooth_loss] + last_metrics)]\r\n",
      "        \u001b[34mfor\u001b[39;49;00m m \u001b[35min\u001b[39;49;00m stats:\r\n",
      "            \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33m#quality_metric: host={HOSTNAME}, epoch={epoch}, {m[0]}={m[1]}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\u001b[37m# The train method\u001b[39;49;00m\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_train\u001b[39;49;00m(args):\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mCalled _train method with parameters:\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mmodel arch: {args.model_arch}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mbatch size: {args.batch_size}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mimage size: {args.image_size}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mepochs: {args.epochs}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mworkers: {args.workers}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mlearn rate: {args.lr}\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33mvalid pct: {args.valid_pct}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mResizing images from: {args.data_dir}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    verify_images(args.data_dir+\u001b[33m'\u001b[39;49;00m\u001b[33m/sport\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, max_size=\u001b[36mint\u001b[39;49;00m(\u001b[34m300\u001b[39;49;00m))\r\n",
      "    verify_images(args.data_dir+\u001b[33m'\u001b[39;49;00m\u001b[33m/metal\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, max_size=\u001b[36mint\u001b[39;49;00m(\u001b[34m300\u001b[39;49;00m))\r\n",
      "\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mGetting training data from dir: {args.data_dir}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    data = (ImageItemList.from_folder(args.data_dir)\r\n",
      "            .random_split_by_pct(args.valid_pct)\r\n",
      "            .label_from_folder()\r\n",
      "            .transform(get_transforms(), size=args.image_size)\r\n",
      "            .databunch(bs=args.batch_size, num_workers=args.workers)\r\n",
      "            .normalize(imagenet_stats))\r\n",
      " \r\n",
      "\u001b[37m#    data = ImageDataBunch.from_folder(args.data_dir, train=\".\", valid_pct=args.valid_pct,\u001b[39;49;00m\r\n",
      "\u001b[37m#                                      ds_tfms=get_transforms(), size=args.image_size, num_workers=args.workers,\u001b[39;49;00m\r\n",
      "\u001b[37m#                                      bs=args.batch_size).normalize(imagenet_stats)\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mClasses are {data.classes}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mModel architecture is {args.model_arch}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    arch = \u001b[36mgetattr\u001b[39;49;00m(models, args.model_arch)\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mCreating pretrained conv net\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    learn = create_cnn(data, arch, metrics=accuracy, callback_fns=[MetricsLogger])\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mFit four cycles with frozen model at lr=1e-2\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\r\n",
      "    learn.fit_one_cycle(\u001b[34m4\u001b[39;49;00m, \u001b[34m1e-2\u001b[39;49;00m)\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mUnfreeze and run {args.epochs} more cycles with lr={args.lr}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    learn.unfreeze()\r\n",
      "    learn.fit_one_cycle(args.epochs, max_lr=\u001b[36mslice\u001b[39;49;00m(args.lr/\u001b[34m10\u001b[39;49;00m,args.lr))\r\n",
      "    \u001b[34mprint\u001b[39;49;00m(f\u001b[33m'\u001b[39;49;00m\u001b[33mSaving model weights to dir: {args.model_dir}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    learn.save(path/args.model_arch)\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mneo_preprocess\u001b[39;49;00m(payload, content_type):\r\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\r\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mio\u001b[39;49;00m\r\n",
      "    \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mfastai\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\r\n",
      "    \u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mfastai.vision\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\r\n",
      "\r\n",
      "    logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mInvoking user-defined pre-processing function\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[34mif\u001b[39;49;00m content_type != \u001b[33m'\u001b[39;49;00m\u001b[33mimage/jpeg\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "        \u001b[34mraise\u001b[39;49;00m \u001b[36mRuntimeError\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mContent type must be image/jpeg\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    f = io.BytesIO(payload)\r\n",
      "    \u001b[37m# Load image\u001b[39;49;00m\r\n",
      "    image = open_image(io.BytesIO(f))\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m image\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mneo_postprocess\u001b[39;49;00m(result):\r\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mlogging\u001b[39;49;00m\r\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\r\n",
      "    \r\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\r\n",
      "    \u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch.nn.functional\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mF\u001b[39;49;00m\r\n",
      "\r\n",
      "    logging.info(\u001b[33m'\u001b[39;49;00m\u001b[33mInvoking user-defined post-processing function\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# Pass output through softmax\u001b[39;49;00m\r\n",
      "    preds = F.softmax(result, dim=\u001b[34m1\u001b[39;49;00m)\r\n",
      "    conf_score, indx = torch.max(preds, dim=\u001b[34m1\u001b[39;49;00m)\r\n",
      "    \u001b[37m# create the response object\u001b[39;49;00m\r\n",
      "    response = {}\r\n",
      "    response[\u001b[33m'\u001b[39;49;00m\u001b[33mclass_idx\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = indx\r\n",
      "    response[\u001b[33m'\u001b[39;49;00m\u001b[33mconfidence\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m] = conf_score.item()\r\n",
      "\r\n",
      "    response_body = json.dumps(response)\r\n",
      "    content_type = \u001b[33m'\u001b[39;49;00m\u001b[33mapplication/json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m response_body, content_type    \r\n",
      "    \r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\r\n",
      "    parser = argparse.ArgumentParser()\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--workers\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m4\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mW\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of data loading workers (default: 4)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m2\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mE\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of total epochs to run (default: 2)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m64\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mBS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mbatch size (default: 64)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--lr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m3e-4\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mLR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minitial learning rate (default: 3e-4)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--valid-pct\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.2\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mVP\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mvalidation data percentage (default: 20\u001b[39;49;00m\u001b[33m%\u001b[39;49;00m\u001b[33m)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)    \r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--momentum\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mfloat\u001b[39;49;00m, default=\u001b[34m0.9\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mM\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, help=\u001b[33m'\u001b[39;49;00m\u001b[33mmomentum (default: 0.9)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--dist-backend\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mgloo\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, help=\u001b[33m'\u001b[39;49;00m\u001b[33mdistributed backend (default: gloo)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "    \u001b[37m# fast.ai specific parameters\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--image-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m224\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mIS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mimage size (default: 224)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-arch\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=\u001b[33m'\u001b[39;49;00m\u001b[33mresnet34\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mMA\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mmodel arch (default: resnet34)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \r\n",
      "    \u001b[37m# The parameters below retrieve their default values from SageMaker environment variables, which are\u001b[39;49;00m\r\n",
      "    \u001b[37m# instantiated by the SageMaker containers framework.\u001b[39;49;00m\r\n",
      "    \u001b[37m# https://github.com/aws/sagemaker-containers#how-a-script-is-executed-inside-the-container\u001b[39;49;00m\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=ast.literal_eval(os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_HOSTS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]))\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CURRENT_HOST\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--num-gpus\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_NUM_GPUS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "\r\n",
      "    _train(parser.parse_args())\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize 'src/shirts-neo/train.py'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more information about training environment variables, please visit [SageMaker Containers](https://github.com/aws/sagemaker-containers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the current example we also need to provide source directory since training script imports data and model classes from other modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "serve.py  train.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls src/shirts-neo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ~/.aws/credentials file (to be removed when local mode is supported)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: this is a temp fix to a problem with running training in local mode. When pull request [here](https://github.com/aws/sagemaker-python-sdk/pull/499) is merged then it can be removed.*\n",
    "\n",
    "A new IAM user needs to be created otherwise the PyTorch local estimator will not work. Create a new IAM User including secret keys and attach the managed policy named `arn:aws:iam::aws:policy/AmazonSageMakerFullAccess`. \n",
    "\n",
    "There is a helper script in `utils/create_save_iam_credentials.sh` that you should run outside this notebook (e.g. on your laptop) that will create the IAM user & access keys and save them into the AWS Secrets Store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pygmentize utils/create_save_iam_credentials.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure you modify the IAM role associated with this SageMaker notebook instance adding the permission to read the secrets store entries. An example AWS CLI command to run on your local laptop that attaches the correct policy to your SageMaker notebook instance IAM role is the following:\n",
    "\n",
    "```\n",
    "aws iam put-role-policy --role-name \"<role-name>\" --policy-name \"secrets\" --policy-document \"{ \\\"Version\\\": \\\"2012-10-17\\\", \\\"Statement\\\": [ { \\\"Effect\\\": \\\"Allow\\\", \\\"Action\\\": \\\"secretsmanager:GetSecretValue\\\", \\\"Resource\\\": \\\"arn:aws:secretsmanager:*:*:secret:SageMakerNb*\\\" } ] }\" \n",
    "```\n",
    "\n",
    "Remember to replace the text `<role-name>` with the name of your role. You can obtain it by running the command in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets the name of the IAM role attached to this notebook instance\n",
    "print(role.rsplit('/', 1)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing new credentials file\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -e ~/.aws/credentials ]; then\n",
    "    echo \"Writing new credentials file\"\n",
    "    accesskey=$(aws secretsmanager get-secret-value --secret-id \"SageMakerNbAccessKey\" --query 'SecretString' --output text)\n",
    "    secretkey=$(aws secretsmanager get-secret-value --secret-id \"SageMakerNbSecretKey\" --query 'SecretString' --output text)\n",
    "\n",
    "    cat > ~/.aws/credentials <<EOF\n",
    "[default]\n",
    "aws_access_key_id=${accesskey}\n",
    "aws_secret_access_key=${secretkey}\n",
    "EOF\n",
    "\n",
    "else\n",
    "    echo \"Credentials file already exists\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure docker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure docker is configured for local training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/SageMaker/sagemaker-fastai-example/utils ~/SageMaker/sagemaker-fastai-example\n",
      "nvidia-docker2 already installed.\n",
      "check if docker config the same\n",
      "Files are the same. Ignoring\n",
      "SageMaker instance route table setup is ok. We are good to go.\n",
      "SageMaker instance routing for Docker is ok. We are good to go!\n",
      "~/SageMaker/sagemaker-fastai-example\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pushd utils\n",
    "bash setup.sh\n",
    "popd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have tested the training and hosting locally, we are ready to train our model using the Amazon SageMaker training service.\n",
    "\n",
    "Training a model on SageMaker with the Python SDK is done in a way that is similar to the way we trained it locally. This is done by changing our train_instance_type from `local` to one of our [supported EC2 instance types](https://aws.amazon.com/sagemaker/pricing/instance-types/).\n",
    "\n",
    "In addition, we must now specify the ECR image URL, which we just pushed above.\n",
    "\n",
    "Finally, our local training dataset has to be in Amazon S3 and the S3 URL to our dataset is passed into the `fit()` call.\n",
    "\n",
    "Let's first fetch our ECR image url that corresponds to the image we just built and pushed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using ECR image for SageMaker training: 934676248949.dkr.ecr.eu-west-1.amazonaws.com/sagemaker-fastai:1.0-gpu-py36\n"
     ]
    }
   ],
   "source": [
    "image_name = f'{account}.dkr.ecr.{region}.amazonaws.com/{base_image_name}:1.0-gpu-py36'\n",
    "print(f'Using ECR image for SageMaker training: {image_name}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create a `PyTorch` estimator object using the SageMaker SDK. The input parameters are almost exactly the same as when we trained locally except we will provide an instance type that will be a specfic instance type used to train the model using the SageMaker training service. In this specific example we will use the `ml.p3.2xlarge` instance type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = PyTorch(entry_point='src/shirts-neo/train.py',\n",
    "                    role=role,\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.p3.2xlarge',\n",
    "                    image_name=image_name,\n",
    "                    framework_version='1',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 6, \n",
    "                        'batch-size': 64\n",
    "                    },\n",
    "                    metric_definitions=[\n",
    "                        {'Name': 'valid:loss',     'Regex': '#quality_metric: host=\\S+, epoch=\\S+, valid_loss=(\\S+)'},\n",
    "                        {'Name': 'train:loss',     'Regex': '#quality_metric: host=\\S+, epoch=\\S+, train_loss=(\\S+)'},\n",
    "                        {'Name': 'valid:accuracy', 'Regex': '#quality_metric: host=\\S+, epoch=\\S+, accuracy=(\\S+)'}\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data location: s3://sagemaker-eu-west-1-934676248949/sagemaker/DEMO-shirts-classification\n"
     ]
    }
   ],
   "source": [
    "data_location=f's3://{bucket_name}/{prefix}'\n",
    "print(f'Training data location: {data_location}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker:Creating training-job with name: fastai-shirts-2018-12-15-21-49-05-449\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-12-15 21:49:06 Starting - Starting the training job...\n",
      "2018-12-15 21:49:10 Starting - Launching requested ML instances......\n",
      "2018-12-15 21:50:07 Starting - Preparing the instances for training...\n",
      "2018-12-15 21:51:01 Downloading - Downloading input data...\n",
      "2018-12-15 21:51:20 Training - Downloading the training image.....\n",
      "\u001b[31mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[31mbash: no job control in this shell\u001b[0m\n",
      "\u001b[31m2018-12-15 21:52:19,481 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[31m2018-12-15 21:52:19,510 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[31m2018-12-15 21:52:20,920 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[31m2018-12-15 21:52:21,166 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[31mGenerating setup.py\u001b[0m\n",
      "\u001b[31m2018-12-15 21:52:21,166 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[31m2018-12-15 21:52:21,166 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[31m2018-12-15 21:52:21,166 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[31mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[31mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-8ddpwmfe/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[31mSuccessfully built train\u001b[0m\n",
      "\u001b[31mInstalling collected packages: train\u001b[0m\n",
      "\u001b[31mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[31m2018-12-15 21:52:22,803 sagemaker-containers INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[31mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[31m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"batch-size\": 64,\n",
      "        \"epochs\": 6\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"job_name\": \"fastai-shirts-2018-12-15-21-49-05-449\",\n",
      "    \"log_level\": 20,\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-eu-west-1-934676248949/fastai-shirts-2018-12-15-21-49-05-449/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"ethwe\",\n",
      "    \"num_cpus\": 8,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"ethwe\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[31m}\n",
      "\u001b[0m\n",
      "\u001b[31mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[31mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[31mSM_NETWORK_INTERFACE_NAME=ethwe\u001b[0m\n",
      "\u001b[31mSM_HPS={\"batch-size\":64,\"epochs\":6}\u001b[0m\n",
      "\u001b[31mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[31mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"}\u001b[0m\n",
      "\u001b[31mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[31mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[31mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[31mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[31mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[31mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[31mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[31mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[31mSM_NUM_CPUS=8\u001b[0m\n",
      "\u001b[31mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[31mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[31mSM_MODULE_DIR=s3://sagemaker-eu-west-1-934676248949/fastai-shirts-2018-12-15-21-49-05-449/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[31mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"batch-size\":64,\"epochs\":6},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"job_name\":\"fastai-shirts-2018-12-15-21-49-05-449\",\"log_level\":20,\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-eu-west-1-934676248949/fastai-shirts-2018-12-15-21-49-05-449/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"ethwe\",\"num_cpus\":8,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"ethwe\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[31mSM_USER_ARGS=[\"--batch-size\",\"64\",\"--epochs\",\"6\"]\u001b[0m\n",
      "\u001b[31mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[31mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[31mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[31mSM_HP_EPOCHS=6\u001b[0m\n",
      "\u001b[31mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\n",
      "\u001b[0m\n",
      "\u001b[31mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[31m/usr/bin/python -m train --batch-size 64 --epochs 6\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[31m2018-12-15 21:52:22,836 sagemaker-containers ERROR    ExecuteUserScriptError:\u001b[0m\n",
      "\u001b[31mCommand \"/usr/bin/python -m train --batch-size 64 --epochs 6\"\u001b[0m\n",
      "\u001b[31mTraceback (most recent call last):\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 183, in _run_module_as_main\n",
      "    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n",
      "  File \"/usr/lib/python3.6/runpy.py\", line 153, in _get_module_details\n",
      "    code = loader.get_code(mod_name)\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n",
      "  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n",
      "  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n",
      "  File \"/opt/ml/code/train.py\", line 78\n",
      "    def neo_preprocess(payload, content_type):\n",
      "    ^\u001b[0m\n",
      "\u001b[31mSyntaxError: import * only allowed at module level\u001b[0m\n",
      "\n",
      "2018-12-15 21:52:26 Uploading - Uploading generated training model\n",
      "2018-12-15 21:52:26 Failed - Training job failed\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error for Training job fastai-shirts-2018-12-15-21-49-05-449: Failed Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/bin/python -m train --batch-size 64 --epochs 6\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/runpy.py\", line 183, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"/usr/lib/python3.6/runpy.py\", line 153, in _get_module_details\n    code = loader.get_code(mod_name)\n  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"/opt/ml/code/train.py\", line 78\n    def neo_preprocess(payload, content_type):\n    ^\nSyntaxError: import * only allowed at module level",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-806b9f63256e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtraining_job_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname_from_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fastai-shirts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name)\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_compilation_job_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, logs)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 573\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogs_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    574\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mlogs_for_job\u001b[0;34m(self, job_name, wait, poll)\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1128\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_job_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'TrainingJobStatus'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1129\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdot\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36m_check_job_status\u001b[0;34m(self, job, desc, status_key_name)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0mreason\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'FailureReason'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'(No reason provided)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m             \u001b[0mjob_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatus_key_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'JobStatus'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' job'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Error for {} {}: {} Reason: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mendpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpoll\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error for Training job fastai-shirts-2018-12-15-21-49-05-449: Failed Reason: AlgorithmError: ExecuteUserScriptError:\nCommand \"/usr/bin/python -m train --batch-size 64 --epochs 6\"\nTraceback (most recent call last):\n  File \"/usr/lib/python3.6/runpy.py\", line 183, in _run_module_as_main\n    mod_name, mod_spec, code = _get_module_details(mod_name, _Error)\n  File \"/usr/lib/python3.6/runpy.py\", line 153, in _get_module_details\n    code = loader.get_code(mod_name)\n  File \"<frozen importlib._bootstrap_external>\", line 781, in get_code\n  File \"<frozen importlib._bootstrap_external>\", line 741, in source_to_code\n  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n  File \"/opt/ml/code/train.py\", line 78\n    def neo_preprocess(payload, content_type):\n    ^\nSyntaxError: import * only allowed at module level"
     ]
    }
   ],
   "source": [
    "training_job_name=name_from_image('fastai-shirts')\n",
    "estimator.fit(data_location, job_name=training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the accuracy metric on a graph pulling the data from CloudWatch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph training metrics from SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframe of training metrics\n",
    "df = TrainingJobAnalytics(training_job_name=training_job_name,metric_names=['train:loss', 'valid:loss', 'valid:accuracy']).dataframe()\n",
    "\n",
    "# plot the dataframe with matplotlib\n",
    "fig, (ax1, ax2) = plt.subplots(1,2, sharey=False)\n",
    "ax1.set_title('Loss')\n",
    "ax1.set_ylabel('loss')\n",
    "for key, grp in df.loc[df['metric_name'] != 'valid:accuracy'].groupby(['metric_name']):\n",
    "    ax = grp.plot(ax=ax1, kind='line', x='timestamp', y='value', label=key)\n",
    "\n",
    "ax2.set_title('Accuracy')\n",
    "ax2.set_ylabel('accuracy')\n",
    "df.loc[df['metric_name'] == 'valid:accuracy'].plot(ax=ax2, kind='line', x='timestamp', y='value', label='accuracy')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile Model with SageMaker Neo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will compile the model with SageMaker Neo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = '/'.join(estimator.output_path.split('/')[:-1])\n",
    "optimized_ic = estimator.compile_model(target_instance_family='ml_c5', \n",
    "                                input_shape={'data':[1, 3, 224, 224]},  # Batch size 1, 3 channels, 224x224 Images.\n",
    "                                output_path=output_path,\n",
    "                                framework='pytorch', framework_version='1.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_ic.name = 'deployed-shirts-classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_ic_classifier = optimized_ic.deploy(initial_instance_count = 1,\n",
    "                                              instance_type = 'ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host model with SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import model into SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since hosting functions implemented outside of train script we can't just use estimator object to deploy the model. Instead we need to create a `PyTorchModel` object using the latest training job to get the S3 location of the trained model data. Besides model data location in S3, we also need to configure `PyTorchModel` with the script and source directory (because our `serve.py` script requires model and data classes from source directory), an IAM role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# always run inference with the cpu based Docker image\n",
    "image_name = f'{account}.dkr.ecr.{region}.amazonaws.com/{base_image_name}:1.0-cpu-py36'\n",
    "print(f'Using ECR image for SageMaker hosting: {image_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PyTorchModel(name=name_from_image('fastai-shirts'),\n",
    "                     model_data=estimator.model_data,\n",
    "                     role=role,\n",
    "                     framework_version='1',\n",
    "                     entry_point='serve.py',\n",
    "                     source_dir='src/shirts',\n",
    "                     image=image_name,\n",
    "                     predictor_cls=ImagePredictor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy model to SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will take the PyTorch specific model created earlier and call the `deploy()` method giving the different instance type so that it will be deployed to the SageMaker hosting service. The instance type does not need to be a GPU instance, a CPU is perfectly fine for model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Call SageMaker endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to call the SageMaker endpoint to see if it is making correct inferences against some test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use on existing endpoint\n",
    "#endpoint_name = 'fastai-shirts-2018-11-27-20-21-19-215'\n",
    "#predictor = ImagePredictor(endpoint_name=endpoint_name, sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motorhead T-Shirt\n",
    "#url = 'https://images.backstreetmerch.com/images/products/bands/clothing/mthd/bsi_mthd281.jpg'\n",
    "# Judas Priest T-Shirt\n",
    "#url = 'https://thumbs2.ebaystatic.com/d/l225/m/m7Lc1qRuFN3oFIlQla5V0IA.jpg'\n",
    "# Iron Maiden T-Shirt\n",
    "#url = 'https://www.ironmaidencollector.com/assets/pages/ab9ed-20180815_121042.jpg'\n",
    "# All Blacks rugby jersey\n",
    "#url = 'https://images.sportsdirect.com/images/products/38153703_l.jpg'\n",
    "# Australia Rugby T-Shirt\n",
    "#url = 'https://www.lovell-rugby.co.uk/products/products_580x387/40378.jpg'\n",
    "# Chicago Bulls top\n",
    "url = 'https://i.ebayimg.com/images/g/qc0AAOSwBahVN~qm/s-l300.jpg'\n",
    "# Masters Golf Shirt\n",
    "#url = 'https://s-media-cache-ak0.pinimg.com/originals/29/6a/15/296a15200e7dd3ed08e12d9052ea4f97.jpg'\n",
    "img_bytes = requests.get(url).content\n",
    "img = Image.open(BytesIO(img_bytes))\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = predictor.predict(img_bytes)\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you're done with the endpoint, you should clean it up.\n",
    "\n",
    "All of the training jobs, models and endpoints we created can be viewed through the SageMaker console of your AWS account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- [How Amazon SageMaker interacts with your Docker container for training](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-training-algo.html)\n",
    "- [How Amazon SageMaker interacts with your Docker container for inference](https://docs.aws.amazon.com/sagemaker/latest/dg/your-algorithms-inference-code.html)\n",
    "- [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk)\n",
    "- [Dockerfile](https://docs.docker.com/engine/reference/builder/)\n",
    "- [PyTorch extending container example](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/pytorch_extending_our_containers/pytorch_extending_our_containers.ipynb)\n",
    "- [scikit-bring-your-own example](https://github.com/awslabs/amazon-sagemaker-examples/blob/master/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb)\n",
    "- [SageMaker fast.ai container](https://github.com/aws-samples/amazon-sagemaker-container-with-fastai)\n",
    "- [SageMaker fast.ai example](https://github.com/mattmcclean/sagemaker-fastai-example)\n",
    "- [SageMaker PyTorch container](https://github.com/aws/sagemaker-pytorch-container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
